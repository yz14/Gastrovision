# 核心原则

## 质量第一
- 宁可多花时间，也要保证代码质量
- 充分思考、分析后再动手实现
- 不要为了快速完成而牺牲代码质量

## 分步完成
- 如果当前对话无法完成所有功能，主动拆分为多轮对话
- 每轮只专注完成一个清晰的目标
- 不贪多，确保每一步都高质量完成

## 充分调研
- 如有需要，充分、彻底地搜索和调研
- 分析和掌握现有的高质量功能实现和算法
- 借鉴业界最佳实践，不要闭门造车

## 调试支持
- 如有需要，可以加入 debug/logging 函数辅助开发
- 通过日志输出帮助定位和解决问题
- 调试代码可在功能稳定后标注或移除

## 沟通规范
- **开始前**：说明你理解的任务目标和将遵守的规则
- **进行中**：如需拆分，明确告知本轮将完成什么
- **完成后**：总结本轮成果，说明后续计划（如有）  


**测试环境为conda activate torch27_env**

# 现状分析  
https://github.com/DebeshJha/GastroVision。这是一个多分类内镜图像识别任务，类别不平衡处理：数据集包含27个类别，共8000张图像，某些病变类别样本极少  


# TODO   
1. 准备用qwen3vl4b-thinking来训练这个分类任务，qwen3vl4b-thinking的huggingface链接https://huggingface.co/Qwen/Qwen3-VL-4B-Thinking。具体做法是，将类别0-26的标签映射为'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'，'0'，这27个字符串，然后做多模态训练，输入为一张图像，输出为一个字符。计算指标的时候需要将字符先转为类别数值，然后再计算。

2. 在main.py里面已经有了用现有的模型运行的过程  

3. 需要在D:\codes\work-projects\Gastrovision_models\vlm_methods里面实现一个训练和预测qwen3vl4b-thinking的代码，需要有清晰的代码和注释; 需要有将数据做成qwen3vl4b-thinking的训练和推理的格式（目前是train.txt, valid.txt, test.txt, class_names.txt）